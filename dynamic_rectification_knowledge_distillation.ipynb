{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGyUVxDT3Lh-",
        "outputId": "3cc64867-ee01-4d87-ef3b-5ffd83f2b914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 3, 2])\n",
            "tensor([2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "Lt1BOcqFMNw6",
        "outputId": "1e5c941b-0d4e-418a-a205-401f8238b720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-09ca1d6a5eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EbKUWCP2P_g"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I08gXM_k2TCO"
      },
      "outputs": [],
      "source": [
        "# setting device on GPU if available, else CPU\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YULsOPv82d0t",
        "outputId": "bda0d7d8-d854-47e7-8eae-38074f430f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Knowledge_Distillation/github_TFKD/Teacher-free-Knowledge-Distillation\n",
            "'=1.10.0'                   \u001b[0m\u001b[01;34mmodel\u001b[0m/\n",
            "'=6.2.2'                    my_loss_function.py\n",
            " anaconda_notebook.ipynb    \u001b[01;34m__pycache__\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/                      README.md\n",
            " data_loader.py             requirements.txt\n",
            " diagrams_for_paper.ipynb   Softmax_Explained.ipynb\n",
            " evaluate.py                TFKD_github.ipynb\n",
            " \u001b[01;34mexperiments\u001b[0m/               tiny_imagenet_custom_dataset.py\n",
            " \u001b[01;34mfigures\u001b[0m/                   \u001b[01;34mtrain\u001b[0m/\n",
            " \u001b[01;34mImageNet_train\u001b[0m/            train_kd.py\n",
            " LICENSE                    utils.py\n",
            " main.py\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/Knowledge_Distillation/github_TFKD/Teacher-free-Knowledge-Distillation/'\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBURx2Mw2guZ"
      },
      "outputs": [],
      "source": [
        "!pip install absl-py\n",
        "!pip install astor\n",
        "!pip install certifi\n",
        "!pip install cffi\n",
        "!pip install chardet\n",
        "!pip install ConfigArgParse\n",
        "!pip install future\n",
        "!pip install gast\n",
        "!pip install grpcio\n",
        "!pip install idna\n",
        "!pip install Markdown\n",
        "!pip install mkl-fft\n",
        "!pip install mkl-random\n",
        "!pip install numpy\n",
        "!pip install olefile\n",
        "!pip install Pillow\n",
        "!pip install protobuf\n",
        "!pip install pycparser\n",
        "!pip install requests\n",
        "!pip install scipy\n",
        "!pip install six\n",
        "!pip install tb-nightly\n",
        "!pip install tensorboard\n",
        "!pip install tensorboardX\n",
        "!pip install tensorflow\n",
        "!pip install termcolor\n",
        "!pip install torch\n",
        "!pip install torchtext\n",
        "!pip install torchvision\n",
        "!pip install tqdm\n",
        "!pip install urllib3\n",
        "!pip install Werkzeug\n",
        "\n",
        "!pip install -U scikit-image\n",
        "#!pip install ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-F9ZHpj2996"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.RandomRotation(20),\n",
        "                transforms.RandomHorizontalFlip(0.5),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.4802, 0.4481, 0.3975], [\n",
        "                                     0.2302, 0.2265, 0.2262]),\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.4802, 0.4481, 0.3975], [\n",
        "                                     0.2302, 0.2265, 0.2262]),\n",
        "            ])\n",
        "        }\n",
        "\n",
        "\n",
        "####################################################\n",
        "#       Create Train and Val sets\n",
        "####################################################\n",
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]\n",
        "\n",
        "\n",
        "def generate_train_val_image_path():\n",
        "    train_data_path = './data/tiny-imagenet-200/train'\n",
        "    val_data_path = './data/tiny-imagenet-200/val'\n",
        "\n",
        "    train_image_paths = []  # to store image paths in list\n",
        "    classes = []  # to store class values\n",
        "\n",
        "    for data_path in glob.glob(train_data_path + '/*'):\n",
        "        classes.append(data_path.split('/')[-1])\n",
        "        train_image_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "    train_image_paths = list(flatten(train_image_paths))\n",
        "    random.shuffle(train_image_paths)\n",
        "\n",
        "    print('train_image_path example: ', train_image_paths[0])\n",
        "    print('class example: ', classes[0])\n",
        "\n",
        "    # 3.\n",
        "    # create the val\n",
        "    val_image_paths = []\n",
        "    for data_path in glob.glob(val_data_path + '/*'):\n",
        "        val_image_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "    val_image_paths = list(flatten(val_image_paths))\n",
        "\n",
        "    print(\"Train size: {}\\nValid size: {}\\n\".format(len(train_image_paths), len(val_image_paths)))\n",
        "\n",
        "    idx_to_class = {i: j for i, j in enumerate(classes)}\n",
        "    class_to_idx = {value: key for key, value in idx_to_class.items()}\n",
        "\n",
        "    return train_image_paths, val_image_paths, idx_to_class, class_to_idx, classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################################################\n",
        "#               Define Dataset Class\n",
        "#######################################################\n",
        "\n",
        "class TinyImagenetDataset(Dataset):\n",
        "    def __init__(self, image_paths, class_to_idx, use_cache = True, cache_size = 50000 ,transform = None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        self.cached_data = []\n",
        "        self.cache_size = cache_size\n",
        "        self.cache = {}\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.cache:\n",
        "            image, label = self.cache[index]\n",
        "        else:\n",
        "            image_filepath = self.image_paths[index]\n",
        "            image_filepath = image_filepath.replace('\\\\', '/')\n",
        "            image = io.imread(image_filepath) # your slow data loading\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            label = image_filepath.split('/')[-2]\n",
        "            label = self.class_to_idx[label]\n",
        "            if len(self.cache) < self.cache_size:\n",
        "                self.cache[index] = (image, label)\n",
        "        \n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_final_train_and_test_set():\n",
        "    train_image_paths, val_image_paths, idx_to_class, class_to_idx, classes = generate_train_val_image_path()\n",
        "    trainset = TinyImagenetDataset(train_image_paths, class_to_idx, transform=data_transforms['train'])\n",
        "    devset = TinyImagenetDataset(val_image_paths, class_to_idx, transform=data_transforms['val'])\n",
        "\n",
        "    return trainset, devset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzUNDqUo2_t5"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "#   Utils\n",
        "##################################################################\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Tensorboard logger code referenced from:\n",
        "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/\n",
        "Other helper functions:\n",
        "https://github.com/cs230-stanford/cs230-stanford.github.io\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc \n",
        "try:\n",
        "    from StringIO import StringIO  # Python 2.7\n",
        "except ImportError:\n",
        "    from io import BytesIO         # Python 3.x\n",
        "\n",
        "\n",
        "class Params():\n",
        "    \"\"\"Class that loads hyperparameters from a json file.\n",
        "\n",
        "    Example:\n",
        "    ```\n",
        "    params = Params(json_path)\n",
        "    print(params.learning_rate)\n",
        "    params.learning_rate = 0.5  # change the value of learning_rate in params\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, json_path):\n",
        "        with open(json_path) as f:\n",
        "            params = json.load(f)\n",
        "            self.__dict__.update(params)\n",
        "\n",
        "    def save(self, json_path):\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(self.__dict__, f, indent=4)\n",
        "            \n",
        "    def update(self, json_path):\n",
        "        \"\"\"Loads parameters from json file\"\"\"\n",
        "        with open(json_path) as f:\n",
        "            params = json.load(f)\n",
        "            self.__dict__.update(params)\n",
        "\n",
        "    @property\n",
        "    def dict(self):\n",
        "        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']\"\"\"\n",
        "        return self.__dict__\n",
        "\n",
        "\n",
        "class RunningAverage():\n",
        "    \"\"\"A simple class that maintains the running average of a quantity\n",
        "    \n",
        "    Example:\n",
        "    ```\n",
        "    loss_avg = RunningAverage()\n",
        "    loss_avg.update(2)\n",
        "    loss_avg.update(4)\n",
        "    loss_avg() = 3\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.steps = 0\n",
        "        self.total = 0\n",
        "    \n",
        "    def update(self, val):\n",
        "        self.total += val\n",
        "        self.steps += 1\n",
        "    \n",
        "    def __call__(self):\n",
        "        return self.total/float(self.steps)\n",
        "\n",
        "class AverageMeter(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val*n\n",
        "        self.count += n\n",
        "        self.avg = self.sum/self.count\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def set_logger(log_path):\n",
        "    \"\"\"Set the logger to log info in terminal and file `log_path`.\n",
        "\n",
        "    In general, it is useful to have a logger so that every output to the terminal is saved\n",
        "    in a permanent file. Here we save it to `model_dir/train.log`.\n",
        "\n",
        "    Example:\n",
        "    ```\n",
        "    logging.info(\"Starting training...\")\n",
        "    ```\n",
        "\n",
        "    Args:\n",
        "        log_path: (string) where to log\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    if not logger.handlers:\n",
        "        # Logging to a file\n",
        "        file_handler = logging.FileHandler(log_path)\n",
        "        file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        # Logging to console\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "def save_dict_to_json(d, json_path):\n",
        "    \"\"\"Saves dict of floats in json file\n",
        "\n",
        "    Args:\n",
        "        d: (dict) of float-castable values (np.float, int, float, etc.)\n",
        "        json_path: (string) path to json file\n",
        "    \"\"\"\n",
        "    with open(json_path, 'w') as f:\n",
        "        # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n",
        "        d = {k: float(v) for k, v in d.items()}\n",
        "        json.dump(d, f, indent=4)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint, epoch_checkpoint = False):\n",
        "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "    checkpoint + 'best.pth.tar'\n",
        "\n",
        "    Args:\n",
        "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
        "        is_best: (bool) True if it is the best model seen till now\n",
        "        checkpoint: (string) folder where parameters are to be saved\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "    if not os.path.exists(checkpoint):\n",
        "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "        os.mkdir(checkpoint)\n",
        "    else:\n",
        "        print(\"Checkpoint Directory exists! \")\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
        "    if epoch_checkpoint == True:\n",
        "        epoch_file = str(state['epoch']-1) + '.pth.tar'\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, epoch_file))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer=None):\n",
        "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
        "    optimizer assuming it is present in checkpoint.\n",
        "\n",
        "    Args:\n",
        "        checkpoint: (string) filename which needs to be loaded\n",
        "        model: (torch.nn.Module) model for which the parameters are loaded\n",
        "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint):\n",
        "        raise(\"File doesn't exist {}\".format(checkpoint))\n",
        "    if torch.cuda.is_available():\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "    else:\n",
        "        # this helps avoid errors when loading single-GPU-trained weights onto CPU-model\n",
        "        checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
        "\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
        "\n",
        "    return checkpoint\n",
        "\n",
        "'''\n",
        "class Board_Logger(object):\n",
        "    \"\"\"Tensorboard log utility\"\"\"\n",
        "    \n",
        "    def __init__(self, log_dir):\n",
        "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
        "        self.writer = tf.summary.FileWriter(log_dir)\n",
        "\n",
        "    def scalar_summary(self, tag, value, step):\n",
        "        \"\"\"Log a scalar variable.\"\"\"\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def image_summary(self, tag, images, step):\n",
        "        \"\"\"Log a list of images.\"\"\"\n",
        "\n",
        "        img_summaries = []\n",
        "        for i, img in enumerate(images):\n",
        "            # Write the image to a string\n",
        "            try:\n",
        "                s = StringIO()\n",
        "            except:\n",
        "                s = BytesIO()\n",
        "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
        "\n",
        "            # Create an Image object\n",
        "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
        "                                       height=img.shape[0],\n",
        "                                       width=img.shape[1])\n",
        "            # Create a Summary value\n",
        "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=img_summaries)\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def histo_summary(self, tag, values, step, bins=1000):\n",
        "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
        "\n",
        "        # Create a histogram using numpy\n",
        "        counts, bin_edges = np.histogram(values, bins=bins)\n",
        "\n",
        "        # Fill the fields of the histogram proto\n",
        "        hist = tf.HistogramProto()\n",
        "        hist.min = float(np.min(values))\n",
        "        hist.max = float(np.max(values))\n",
        "        hist.num = int(np.prod(values.shape))\n",
        "        hist.sum = float(np.sum(values))\n",
        "        hist.sum_squares = float(np.sum(values**2))\n",
        "\n",
        "        # Drop the start of the first bin\n",
        "        bin_edges = bin_edges[1:]\n",
        "\n",
        "        # Add bin edges and counts\n",
        "        for edge in bin_edges:\n",
        "            hist.bucket_limit.append(edge)\n",
        "        for c in counts:\n",
        "            hist.bucket.append(c)\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "        self.writer.flush\n",
        "'''\n",
        "\n",
        "class WarmUpLR(_LRScheduler):\n",
        "    \"\"\"warmup_training learning rate scheduler\n",
        "    Args:\n",
        "        optimizer: optimzier(e.g. SGD)\n",
        "        total_iters: totoal_iters of warmup phase\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
        "        self.total_iters = total_iters\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        \"\"\"we will use the first m batches, and set the learning\n",
        "        rate to base_lr * m / total_iters\n",
        "        \"\"\"\n",
        "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oydFZd_m3BLh"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "#   Data Loader\n",
        "##################################################################\n",
        "\n",
        "\"\"\"\n",
        "   CIFAR-10 CIFAR-100, Tiny-ImageNet data loader\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "def fetch_dataloader(types, params, dataset_name=None):\n",
        "    \"\"\"\n",
        "    Fetch and return train/dev dataloader with hyperparameters (params.subset_percent = 1.)\n",
        "    \"\"\"\n",
        "    # using random crops and horizontal flip for train set\n",
        "    if params.augmentation == \"yes\":\n",
        "        train_transformer = transforms.Compose([\n",
        "            transforms.RandomCrop(\n",
        "                32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343),\n",
        "                                 (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n",
        "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.240, 0.243, 0.261))\n",
        "\n",
        "    # data augmentation can be turned off\n",
        "    else:\n",
        "        train_transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343),\n",
        "                                 (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n",
        "\n",
        "    # transformer for dev set\n",
        "    dev_transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343),\n",
        "                             (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n",
        "\n",
        "    # Deciding Dataset\n",
        "    if dataset_name == None:\n",
        "        if params.dataset == 'cifar10':\n",
        "            trainset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=True,\n",
        "                                                    download=True, transform=train_transformer)\n",
        "            devset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=False,\n",
        "                                                  download=True, transform=dev_transformer)\n",
        "        elif params.dataset == 'cifar100':\n",
        "            trainset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=True,\n",
        "                                                     download=True, transform=train_transformer)\n",
        "            devset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=False,\n",
        "                                                   download=True, transform=dev_transformer)\n",
        "        elif params.dataset == 'mnist':\n",
        "            trainset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=True,\n",
        "                                                  download=True, transform=train_transformer)\n",
        "            devset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=False,\n",
        "                                                download=True, transform=dev_transformer)\n",
        "        elif params.dataset == 'tiny_imagenet':\n",
        "            trainset, devset = get_final_train_and_test_set()\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Dataset Name :  ----------     \" + str(dataset_name) + \"     ----------\")\n",
        "        if dataset_name == 'cifar10':\n",
        "            trainset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=True,\n",
        "                                                    download=True, transform=train_transformer)\n",
        "            devset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=False,\n",
        "                                                  download=True, transform=dev_transformer)\n",
        "        elif dataset_name == 'cifar100':\n",
        "            trainset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=True,\n",
        "                                                     download=True, transform=train_transformer)\n",
        "            devset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=False,\n",
        "                                                   download=True, transform=dev_transformer)\n",
        "        elif dataset_name == 'mnist':\n",
        "            trainset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=True,\n",
        "                                                  download=True, transform=train_transformer)\n",
        "            devset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=False,\n",
        "                                                download=True, transform=dev_transformer)\n",
        "        elif dataset_name == 'tiny_imagenet':\n",
        "            trainset, devset = get_final_train_and_test_set()\n",
        "            # data_dir = './data/tiny-imagenet-200/'\n",
        "            # data_transforms = {\n",
        "            #     'train': transforms.Compose([\n",
        "            #         transforms.RandomRotation(20),\n",
        "            #         transforms.RandomHorizontalFlip(0.5),\n",
        "            #         transforms.ToTensor(),\n",
        "            #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "            #     ]),\n",
        "            #     'val': transforms.Compose([\n",
        "            #         transforms.ToTensor(),\n",
        "            #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "            #     ])\n",
        "            # }\n",
        "            # train_dir = data_dir + 'train/'\n",
        "            # test_dir = data_dir + 'val/'\n",
        "            # trainset = torchvision.datasets.ImageFolder(train_dir, data_transforms['train'])\n",
        "            # devset = torchvision.datasets.ImageFolder(test_dir, data_transforms['val'])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=params.batch_size, shuffle=True, num_workers=params.num_workers)\n",
        "    devloader = torch.utils.data.DataLoader(devset, batch_size=params.batch_size, shuffle=False, num_workers=params.num_workers)\n",
        "\n",
        "    if types == 'train':\n",
        "        dl = trainloader\n",
        "    else:\n",
        "        dl = devloader\n",
        "\n",
        "    return dl\n",
        "\n",
        "\n",
        "def fetch_subset_dataloader(types, params):\n",
        "    \"\"\"\n",
        "    Use only a subset of dataset for KD training, depending on params.subset_percent\n",
        "    \"\"\"\n",
        "\n",
        "    # using random crops and horizontal flip for train set\n",
        "    if params.augmentation == \"yes\":\n",
        "        train_transformer = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "    # data augmentation can be turned off\n",
        "    else:\n",
        "        train_transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "    # transformer for dev set\n",
        "    dev_transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "    if params.dataset == 'cifar10':\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=True,\n",
        "                                                download=True, transform=train_transformer)\n",
        "        devset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=False,\n",
        "                                              download=True, transform=dev_transformer)\n",
        "    elif params.dataset == 'cifar100':\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=True,\n",
        "                                                download=True, transform=train_transformer)\n",
        "        devset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=False,\n",
        "                                              download=True, transform=dev_transformer)\n",
        "    elif params.dataset == 'tiny_imagenet':\n",
        "        trainset, devset = get_final_train_and_test_set()\n",
        "        # data_dir = './data/tiny-imagenet-200/'\n",
        "        # data_transforms = {\n",
        "        #     'train': transforms.Compose([\n",
        "        #         transforms.RandomRotation(20),\n",
        "        #         transforms.RandomHorizontalFlip(0.5),\n",
        "        #         transforms.ToTensor(),\n",
        "        #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "        #     ]),\n",
        "        #     'val': transforms.Compose([\n",
        "        #         transforms.ToTensor(),\n",
        "        #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "        #     ])\n",
        "        # }\n",
        "        # train_dir = data_dir + 'train/'\n",
        "        # test_dir = data_dir + 'val/'\n",
        "        # trainset = torchvision.datasets.ImageFolder(train_dir, data_transforms['train'])\n",
        "        # devset = torchvision.datasets.ImageFolder(test_dir, data_transforms['val'])\n",
        "\n",
        "    trainset_size = len(trainset)\n",
        "    indices = list(range(trainset_size))\n",
        "    split = int(np.floor(params.subset_percent * trainset_size))\n",
        "    np.random.seed(230)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(indices[:split])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=params.batch_size,\n",
        "                                              sampler=train_sampler, num_workers=params.num_workers)\n",
        "\n",
        "    devloader = torch.utils.data.DataLoader(devset, batch_size=params.batch_size,\n",
        "                                            shuffle=False, num_workers=params.num_workers)\n",
        "\n",
        "    if types == 'train':\n",
        "        dl = trainloader\n",
        "    else:\n",
        "        dl = devloader\n",
        "\n",
        "    return dl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofTgWLb83DCj"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "#   Evaluate\n",
        "##################################################################\n",
        "\n",
        "\"\"\"Evaluates the model\"\"\"\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_dir', default='experiments/base_model',\n",
        "                    help=\"Directory of params.json\")\n",
        "parser.add_argument('--restore_file', default='best', help=\"name of the file in --model_dir \\\n",
        "                     containing weights to load\")\n",
        "\n",
        "\n",
        "def evaluate(model, loss_fn, dataloader, params, args):\n",
        "    \"\"\"Evaluate the model on `num_steps` batches.\n",
        "\n",
        "    Args:\n",
        "        model: (torch.nn.Module) the neural network\n",
        "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
        "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n",
        "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
        "        params: (Params) hyperparameters\n",
        "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # compute metrics over the dataset\n",
        "    for data_batch, labels_batch in dataloader:\n",
        "        data_batch, labels_batch = data_batch.to(device), labels_batch.to(device)\n",
        "\n",
        "        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n",
        "        # compute model output\n",
        "        output_batch = model(data_batch)\n",
        "        if args.regularization:\n",
        "            loss = loss_fn(output_batch, labels_batch, params)\n",
        "        else:\n",
        "            loss = loss_fn(output_batch, labels_batch)\n",
        "\n",
        "        losses.update(loss.data, data_batch.size(0))\n",
        "        _, predicted = output_batch.max(1)\n",
        "        total += labels_batch.size(0)\n",
        "        correct += predicted.eq(labels_batch).sum().item()\n",
        "\n",
        "    loss_avg = losses.avg\n",
        "    acc = 100.*correct/total\n",
        "    logging.info(\n",
        "        \"- Eval metrics, acc:{acc:.4f}, loss: {loss_avg:.4f}\".format(acc=acc, loss_avg=loss_avg))\n",
        "    my_metric = {'accuracy': acc, 'loss': loss_avg}\n",
        "    return my_metric\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This function duplicates \"evaluate()\" but ignores \"loss_fn\" simply for speedup purpose.\n",
        "Validation loss during KD mode would display '0' all the time.\n",
        "One can bring that info back by using the fetched teacher outputs during evaluation (refer to train.py)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def evaluate_kd(model, dataloader, params):\n",
        "    \"\"\"Evaluate the model on `num_steps` batches.\n",
        "\n",
        "    Args:\n",
        "        model: (torch.nn.Module) the neural network\n",
        "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
        "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n",
        "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
        "        params: (Params) hyperparameters\n",
        "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # compute metrics over the dataset\n",
        "    for i, (data_batch, labels_batch) in enumerate(dataloader):\n",
        "        # move to GPU if available\n",
        "        data_batch, labels_batch = data_batch.to(device), labels_batch.to(device)\n",
        "        # fetch the next evaluation batch\n",
        "        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n",
        "\n",
        "        # compute model output\n",
        "        output_batch = model(data_batch)\n",
        "\n",
        "        # loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params)\n",
        "        loss = 0.0  # force validation loss to zero to reduce computation time\n",
        "        _, predicted = output_batch.max(1)\n",
        "        total += labels_batch.size(0)\n",
        "        correct += predicted.eq(labels_batch).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    logging.info(\"- Eval metrics, acc:{acc:.4f}, loss: {loss:.4f}\".format(acc=acc, loss=loss))\n",
        "    my_metric = {'accuracy': acc, 'loss': loss}\n",
        "    #my_metric['accuracy'] = acc\n",
        "    return my_metric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvwDgGPs3bmS"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "#   My loss functions\n",
        "##################################################################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def loss_kd(outputs, labels, teacher_outputs, params):\n",
        "    \"\"\"\n",
        "    loss function for Knowledge Distillation (KD)\n",
        "    \"\"\"\n",
        "    alpha = params.alpha\n",
        "    T = params.temperature\n",
        "\n",
        "    loss_CE = F.cross_entropy(outputs, labels)\n",
        "    D_KL = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n",
        "                          F.softmax(teacher_outputs/T, dim=1)) * (T * T)\n",
        "    KD_loss = (1. - alpha)*loss_CE + alpha*D_KL\n",
        "\n",
        "    return KD_loss\n",
        "\n",
        "\n",
        "# def dynamic_rectification(outputs, labels):\n",
        "#     _, predicted = outputs.max(1)\n",
        "#     correct = predicted.eq(labels)\n",
        "\n",
        "#     for i in range(correct.shape[0]):\n",
        "#         if correct[i].item() == False:\n",
        "#             c_index = labels[i].item()\n",
        "#             p_index = predicted[i].item()\n",
        "#             tmp1, tmp2 = outputs[i, p_index].item(), outputs[i, c_index].item()\n",
        "#             outputs[i, c_index] = tmp1\n",
        "#             outputs[i, p_index] = tmp2\n",
        "    \n",
        "#     return outputs\n",
        "\n",
        "def loss_swap(outputs, labels):\n",
        "    _, predicted = outputs.max(1)\n",
        "    tmp = outputs[torch.arange(len(labels)), predicted]\n",
        "    outputs[torch.arange(len(labels)), predicted] = outputs[torch.arange(\n",
        "        len(labels)), labels]\n",
        "    outputs[torch.arange(len(labels)), labels] = tmp\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def loss_kd_self(outputs, labels, teacher_outputs, params, swap_option='None'):\n",
        "    \"\"\"\n",
        "    loss function for self training: Tf-KD_{self}\n",
        "    \"\"\"\n",
        "    alpha = params.alpha\n",
        "    T = params.temperature\n",
        "    \"\"\"\n",
        "        Swapping the outputs here\n",
        "        student_probability_swap || teacher_probability_swap \n",
        "    \"\"\"\n",
        "    if swap_option == 'student_probability_swap':\n",
        "        outputs = loss_swap(outputs, labels)\n",
        "    elif swap_option == 'teacher_probability_swap':\n",
        "        teacher_outputs = loss_swap(teacher_outputs, labels)\n",
        "\n",
        "    loss_CE = F.cross_entropy(outputs, labels)\n",
        "    D_KL = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1)) * \\\n",
        "        (T * T) * params.multiplier  # multiple is 1.0 in most of cases, some cases are 10 or 50\n",
        "    KD_loss = (1. - alpha)*loss_CE + alpha*D_KL\n",
        "\n",
        "    return KD_loss\n",
        "\n",
        "\n",
        "def loss_kd_regularization(outputs, labels, params):\n",
        "    \"\"\"\n",
        "    loss function for mannually-designed regularization: Tf-KD_{reg}\n",
        "    \"\"\"\n",
        "    alpha = params.reg_alpha\n",
        "    T = params.reg_temperature\n",
        "    correct_prob = 0.99    # the probability for correct class in u(k)\n",
        "    loss_CE = F.cross_entropy(outputs, labels)\n",
        "    K = outputs.size(1)\n",
        "\n",
        "    teacher_soft = torch.ones_like(outputs).to(device)\n",
        "    teacher_soft = teacher_soft*(1-correct_prob)/(K-1)  # p^d(k)\n",
        "    for i in range(outputs.shape[0]):\n",
        "        teacher_soft[i, labels[i]] = correct_prob\n",
        "    loss_soft_regu = nn.KLDivLoss()(F.log_softmax(outputs, dim=1),\n",
        "                                    F.softmax(teacher_soft/T, dim=1))*params.multiplier\n",
        "\n",
        "    KD_loss = (1. - alpha)*loss_CE + alpha*loss_soft_regu\n",
        "\n",
        "    return KD_loss\n",
        "\n",
        "\n",
        "def loss_kd_self_plus_regularization(outputs, labels, teacher_outputs, params, swap_option='None'):\n",
        "\n",
        "    new_alpha = 0.45\n",
        "   \n",
        "    #loss function for self training: Tf-KD_{self}\n",
        "    alpha_self = params.alpha\n",
        "    T = params.temperature\n",
        "    \"\"\"\n",
        "        Swapping the outputs here\n",
        "        student_probability_swap || teacher_probability_swap \n",
        "    \"\"\"\n",
        "    if swap_option == 'student_probability_swap':\n",
        "        outputs = loss_swap(outputs, labels)\n",
        "    elif swap_option == 'teacher_probability_swap':\n",
        "        teacher_outputs = loss_swap(teacher_outputs, labels)\n",
        "\n",
        "    loss_CE = F.cross_entropy(outputs, labels)\n",
        "    D_KL_Self = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1)) * \\\n",
        "        (T * T) * params.multiplier  # multiple is 1.0 in most of cases, some cases are 10 or 50\n",
        "    \n",
        "\n",
        "\n",
        "    #loss function for mannually-designed regularization: Tf-KD_{reg}\n",
        "    alpha_reg = params.reg_alpha\n",
        "    T = params.reg_temperature\n",
        "    correct_prob = 0.99    # the probability for correct class in u(k)\n",
        "    loss_CE = F.cross_entropy(outputs, labels)\n",
        "    K = outputs.size(1)\n",
        "\n",
        "    teacher_soft = torch.ones_like(outputs).to(device)\n",
        "    teacher_soft = teacher_soft*(1-correct_prob)/(K-1)  # p^d(k)\n",
        "    for i in range(outputs.shape[0]):\n",
        "        teacher_soft[i, labels[i]] = correct_prob\n",
        "    loss_soft_regu = nn.KLDivLoss()(F.log_softmax(outputs, dim=1),F.softmax(teacher_soft/T, dim=1))*params.multiplier\n",
        "\n",
        "\n",
        "\n",
        "    # final loss \n",
        "    KD_loss = (1. - alpha_reg)*loss_CE + new_alpha*loss_soft_regu + new_alpha*D_KL_Self\n",
        "\n",
        "    return KD_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loss_label_smoothing(outputs, labels):\n",
        "    \"\"\"\n",
        "    loss function for label smoothing regularization\n",
        "    \"\"\"\n",
        "    alpha = 0.1\n",
        "    N = outputs.size(0)  # batch_size\n",
        "    C = outputs.size(1)  # number of classes\n",
        "    smoothed_labels = torch.full(\n",
        "        size=(N, C), fill_value=alpha / (C - 1)).to(device)\n",
        "    smoothed_labels.scatter_(\n",
        "        dim=1, index=torch.unsqueeze(labels, dim=1), value=1-alpha)\n",
        "\n",
        "    log_prob = torch.nn.functional.log_softmax(outputs, dim=1)\n",
        "    loss = -torch.sum(log_prob * smoothed_labels) / N\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqzn15bF3dJK"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "#   Train functions\n",
        "##################################################################\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
        "\n",
        "\n",
        "# KD train and evaluate\n",
        "def train_and_evaluate_kd(model, teacher_model, train_dataloader, val_dataloader, optimizer,\n",
        "                       loss_fn_kd, warmup_scheduler, params, args, restore_file=None):\n",
        "    \"\"\"\n",
        "    KD Train the model and evaluate every epoch.\n",
        "    \"\"\"\n",
        "    # reload weights from restore_file if specified\n",
        "    if restore_file is not None:\n",
        "        restore_path = os.path.join(args.model_dir, args.restore_file + '.pth.tar')\n",
        "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
        "        load_checkpoint(restore_path, model, optimizer)\n",
        "\n",
        "    # tensorboard setting\n",
        "    log_dir = args.model_dir + '/tensorboard/'\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    teacher_model.eval()\n",
        "    teacher_acc = evaluate_kd(teacher_model, val_dataloader, params)\n",
        "    print(\">>>>>>>>>The teacher accuracy: {}>>>>>>>>>\".format(teacher_acc['accuracy']))\n",
        "\n",
        "    scheduler = MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
        "    for epoch in range(params.num_epochs):\n",
        "\n",
        "        if epoch > 0:   # 0 is the warm up epoch\n",
        "            scheduler.step()\n",
        "        logging.info(\"Epoch {}/{}, lr:{}\".format(epoch + 1, params.num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "        # KD Train\n",
        "        train_acc, train_loss = train_kd(model, teacher_model, optimizer, loss_fn_kd, train_dataloader, warmup_scheduler, params, args, epoch)\n",
        "        # Evaluate\n",
        "        val_metrics = evaluate_kd(model, val_dataloader, params)\n",
        "\n",
        "        val_acc = val_metrics['accuracy']\n",
        "        is_best = val_acc>=best_val_acc\n",
        "\n",
        "        # Save weights\n",
        "        save_checkpoint({'epoch': epoch + 1,\n",
        "                               'state_dict': model.state_dict(),\n",
        "                               'optim_dict' : optimizer.state_dict()},\n",
        "                               is_best=is_best,\n",
        "                               checkpoint=args.model_dir)\n",
        "\n",
        "        # If best_eval, best_save_path\n",
        "        if is_best:\n",
        "            logging.info(\"*********** Hurray ! Found new best accuracy *****************\")\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            # Save best val metrics in a json file in the model directory\n",
        "            file_name = \"eval_best_result.json\"\n",
        "            best_json_path = os.path.join(args.model_dir, file_name)\n",
        "            save_dict_to_json(val_metrics, best_json_path)\n",
        "\n",
        "        # Save latest val metrics in a json file in the model directory\n",
        "        last_json_path = os.path.join(args.model_dir, \"eval_last_result.json\")\n",
        "        save_dict_to_json(val_metrics, last_json_path)\n",
        "\n",
        "        # Tensorboard\n",
        "        writer.add_scalar('Train_accuracy', train_acc, epoch)\n",
        "        writer.add_scalar('Train_loss', train_loss, epoch)\n",
        "        writer.add_scalar('Test_accuracy', val_metrics['accuracy'], epoch)\n",
        "        writer.add_scalar('Test_loss', val_metrics['loss'], epoch)\n",
        "        # export scalar data to JSON for external processing\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "# Defining train_kd functions\n",
        "def train_kd(model, teacher_model, optimizer, loss_fn_kd, dataloader, warmup_scheduler, params, args, epoch, flag=None):\n",
        "    \"\"\"\n",
        "    KD Train the model on `num_steps` batches\n",
        "    \"\"\"\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    teacher_model.eval()\n",
        "    loss_avg = RunningAverage()\n",
        "    losses = AverageMeter()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    # Use tqdm for progress bar\n",
        "    with tqdm(total=len(dataloader)) as t:\n",
        "        for i, (train_batch, labels_batch) in enumerate(dataloader):\n",
        "            if epoch<=0:\n",
        "                warmup_scheduler.step()\n",
        "\n",
        "            train_batch, labels_batch = train_batch.to(device), labels_batch.to(device)\n",
        "            # convert to torch Variables\n",
        "            train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n",
        "\n",
        "            # compute model output, fetch teacher output, and compute KD loss\n",
        "            output_batch = model(train_batch)\n",
        "\n",
        "            # get one batch output from teacher model\n",
        "            output_teacher_batch = teacher_model(train_batch).to(device)\n",
        "            output_teacher_batch = Variable(output_teacher_batch, requires_grad=False)\n",
        "\n",
        "            loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params, args.swap_option)\n",
        "\n",
        "            # clear previous gradients, compute gradients of all variables wrt loss\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # performs updates using calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = output_batch.max(1)\n",
        "            total += labels_batch.size(0)\n",
        "            correct += predicted.eq(labels_batch).sum().item()\n",
        "            # update the average loss\n",
        "            loss_avg.update(loss.data)\n",
        "            losses.update(loss.item(), train_batch.size(0))\n",
        "\n",
        "            t.set_postfix(loss='{:05.3f}'.format(loss_avg()), lr='{:05.6f}'.format(optimizer.param_groups[0]['lr']))\n",
        "            t.update()\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    logging.info(\"- Train accuracy: {acc:.4f}, training loss: {loss:.4f}\".format(acc = acc, loss = losses.avg))\n",
        "    return acc, losses.avg\n",
        "\n",
        "\n",
        "# normal training\n",
        "def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n",
        "                       loss_fn, params, model_dir, warmup_scheduler, args, restore_file=None):\n",
        "    \"\"\"\n",
        "    Train the model and evaluate every epoch.\n",
        "    \"\"\"\n",
        "    # reload weights from restore_file if specified\n",
        "    if restore_file is not None:\n",
        "        restore_path = os.path.join(args.model_dir, args.restore_file + '.pth.tar')\n",
        "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
        "        load_checkpoint(restore_path, model, optimizer)\n",
        "\n",
        "    # dir setting, tensorboard events will save in the dirctory\n",
        "    log_dir = args.model_dir + '/base_train/'\n",
        "    if args.regularization:\n",
        "        log_dir = args.model_dir + '/Tf-KD_regularization/'\n",
        "        model_dir = log_dir\n",
        "    elif args.label_smoothing:\n",
        "        log_dir = args.model_dir + '/label_smoothing/'\n",
        "        model_dir = log_dir\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    # learning rate schedulers\n",
        "    scheduler = MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
        "\n",
        "    for epoch in range(params.num_epochs):\n",
        "        if epoch > 0:   # 1 is the warm up epoch\n",
        "            scheduler.step(epoch)\n",
        "\n",
        "        # Run one epoch\n",
        "        logging.info(\"Epoch {}/{}, lr:{}\".format(epoch + 1, params.num_epochs, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "        # compute number of batches in one epoch (one full pass over the training set)\n",
        "        train_acc, train_loss = train(model, optimizer, loss_fn, train_dataloader, params, epoch, warmup_scheduler, args)\n",
        "\n",
        "        # Evaluate for one epoch on validation set\n",
        "        val_metrics = evaluate(model, loss_fn, val_dataloader, params, args)\n",
        "\n",
        "        val_acc = val_metrics['accuracy']\n",
        "        is_best = val_acc>=best_val_acc\n",
        "\n",
        "        # Save weights\n",
        "        save_checkpoint({'epoch': epoch + 1,\n",
        "                               'state_dict': model.state_dict(),\n",
        "                               'optim_dict' : optimizer.state_dict()},\n",
        "                                is_best=is_best,\n",
        "                                checkpoint=model_dir)\n",
        "        # If best_eval, best_save_path\n",
        "        if is_best:\n",
        "            logging.info(\"- Found new best accuracy\")\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            # Save best val metrics in a json file in the model directory\n",
        "            best_json_path = os.path.join(model_dir, \"eval_best_results.json\")\n",
        "            save_dict_to_json(val_metrics, best_json_path)\n",
        "\n",
        "        # Save latest val metrics in a json file in the model directory\n",
        "        last_json_path = os.path.join(model_dir, \"eval_last_results.json\")\n",
        "        save_dict_to_json(val_metrics, last_json_path)\n",
        "\n",
        "        # Tensorboard\n",
        "        writer.add_scalar('Train_accuracy', train_acc, epoch)\n",
        "        writer.add_scalar('Train_loss', train_loss, epoch)\n",
        "        writer.add_scalar('Test_accuracy', val_metrics['accuracy'], epoch)\n",
        "        writer.add_scalar('Test_loss', val_metrics['loss'], epoch)\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "# normal training function\n",
        "def train(model, optimizer, loss_fn, dataloader, params, epoch, warmup_scheduler, args):\n",
        "    \"\"\"\n",
        "    Noraml training, without KD\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    loss_avg = RunningAverage()\n",
        "    losses = AverageMeter()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    with tqdm(total=len(dataloader)) as t:\n",
        "        for i, data in enumerate(dataloader):\n",
        "            # print(data)\n",
        "            train_batch, labels_batch = data\n",
        "            train_batch, labels_batch = train_batch.cuda(), labels_batch.cuda()\n",
        "            if epoch<=0:\n",
        "                warmup_scheduler.step()\n",
        "            train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            print(train_batch.shape)\n",
        "            output_batch = model(train_batch)\n",
        "            \n",
        "            if args.regularization:\n",
        "                loss = loss_fn(output_batch, labels_batch, params)\n",
        "            else:\n",
        "                loss = loss_fn(output_batch, labels_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = output_batch.max(1)\n",
        "            total += labels_batch.size(0)\n",
        "            correct += predicted.eq(labels_batch).sum().item()\n",
        "\n",
        "            # update the average loss\n",
        "            loss_avg.update(loss.data)\n",
        "            losses.update(loss.data, train_batch.size(0))\n",
        "\n",
        "            t.set_postfix(loss='{:05.3f}'.format(loss_avg()), lr='{:05.6f}'.format(optimizer.param_groups[0]['lr']))\n",
        "            t.update()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    logging.info(\"- Train accuracy: {acc: .4f}, training loss: {loss: .4f}\".format(acc=acc, loss=losses.avg))\n",
        "    return acc, losses.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoL7Y0uV3fGp"
      },
      "outputs": [],
      "source": [
        "def read_params_json(json_path):\n",
        "    f = open(json_path)\n",
        "    json_object = json.load(f)\n",
        "    print(\"################## Json Params ##################\")\n",
        "    json_formatted_str = json.dumps(json_object, indent=2)\n",
        "    print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efubCvup3gfx"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "\n",
        "    elif model_name == \"densenet121\":\n",
        "        \"\"\" Densenet121\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpoJz6Hz3h6B"
      },
      "outputs": [],
      "source": [
        " class ArmentPassingClass:\n",
        "  def __init__(self, model_dir, restore_file, num_class, warm, regularization, label_smoothing, double_training, \n",
        "               self_training, swap_option, dataset_name, random_seeder, pt_teacher):\n",
        "    self.model_dir = model_dir\n",
        "    self.restore_file = restore_file\n",
        "    self.num_class = num_class\n",
        "    self.warm = warm\n",
        "    self.regularization = regularization\n",
        "    self.label_smoothing = label_smoothing\n",
        "    self.double_training = double_training\n",
        "    self.self_training = self_training\n",
        "    self.swap_option = swap_option\n",
        "    self.dataset_name = dataset_name\n",
        "    self.random_seeder = random_seeder\n",
        "    self.pt_teacher = pt_teacher\n",
        "\n",
        "dataset_num_class_dict = {'cifar10': 10, 'cifar100': 100, 'tiny_imagenet':200}\n",
        "\n",
        "\n",
        "############# Dataset Assigning #############\n",
        "dataset_name = 'tiny_imagenet' \n",
        "num_class = dataset_num_class_dict[dataset_name]\n",
        "restore_file = None\n",
        "\n",
        "\n",
        "############# KD Train #############\n",
        "# model_dir =  'experiments/kd_experiments/shufflenet_distill/shufflenet_self_teacher/' + dataset_name\n",
        "# model_dir =  'experiments/kd_experiments/resnet50_distill/resnet50_self_teacher/' + dataset_name\n",
        "# model_dir =  'experiments/kd_experiments/densenet121_distill/densenet_self_teacher/' + dataset_name\n",
        "# model_dir =  'experiments/kd_experiments/googlenet_distill/googlenet_self_teacher/' + dataset_name\n",
        "# self_training = True\n",
        "# swap_option = 'teacher_probability_swap'\n",
        "\n",
        "\n",
        "\n",
        "############# Base Train #############  \n",
        "# # model_dir =  'experiments/base_experiments/base_shufflenetv2/' + dataset_name\n",
        "model_dir =  'experiments/base_experiments/base_resnet50/' + dataset_name\n",
        "# model_dir =  'experiments/base_experiments/base_densenet121/' + dataset_name\n",
        "self_training = False\n",
        "swap_option = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "args = ArmentPassingClass(  model_dir = model_dir, \n",
        "                            restore_file = restore_file, \n",
        "                            num_class = num_class, \n",
        "                            warm = 1, \n",
        "                            regularization = False, \n",
        "                            label_smoothing = False, \n",
        "                            double_training = False, \n",
        "                            self_training = self_training, \n",
        "                            swap_option = swap_option, \n",
        "                            dataset_name = dataset_name, \n",
        "                            random_seeder = 2320, \n",
        "                            pt_teacher = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "fwEVptNK3jLQ",
        "outputId": "5ac8e3d5-98a2-41dd-a9e9-bb3460ec3194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################## Json Params ##################\n",
            "{\n",
            "  \"model_version\": \"resnet50\",\n",
            "  \"subset_percent\": 1.0,\n",
            "  \"augmentation\": \"yes\",\n",
            "  \"teacher\": \"none\",\n",
            "  \"alpha\": 0.0,\n",
            "  \"temperature\": 1,\n",
            "  \"learning_rate\": 0.1,\n",
            "  \"batch_size\": 32,\n",
            "  \"num_epochs\": 200,\n",
            "  \"dropout_rate\": 0.5,\n",
            "  \"num_channels\": 32,\n",
            "  \"save_summary_steps\": 100,\n",
            "  \"num_workers\": 4,\n",
            "  \"dataset\": \"tiny_imagenet\"\n",
            "}\n",
            "Random Seeder :  2320\n",
            "Dataset Name :  tiny_imagenet   Number of classes:  200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading the datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Name :  ----------     tiny_imagenet     ----------\n",
            "train_image_path example:  ./data/tiny-imagenet-200/train/n02977058/n02977058_258.JPEG\n",
            "class example:  n02106662\n",
            "Train size: 100000\n",
            "Valid size: 10000\n",
            "\n",
            "Dataset Name :  ----------     tiny_imagenet     ----------\n",
            "train_image_path example:  ./data/tiny-imagenet-200/train/n04376876/n04376876_349.JPEG\n",
            "class example:  n02106662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "- done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 100000\n",
            "Valid size: 10000\n",
            "\n",
            "Train base model\n",
            "model: resnet50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-0233cd26f1bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-0233cd26f1bc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"resnet101\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.75 GiB already allocated; 3.75 MiB free; 14.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "##################################################################\n",
        "#   Main\n",
        "##################################################################\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Teacher free KD, main.py\n",
        "\"\"\"\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "\n",
        "# import data_loader as data_loader\n",
        "import model.alexnet as alexnet\n",
        "import model.densenet as densenet\n",
        "import model.googlenet as googlenet\n",
        "import model.mobilenetv2 as mobilenet\n",
        "import model.net as net\n",
        "import model.resnet as resnet\n",
        "import model.resnext as resnext\n",
        "import model.shufflenetv2 as shufflenet\n",
        "# import utils\n",
        "# from my_loss_function import (loss_kd, loss_kd_regularization, loss_kd_self,\n",
        "#                               loss_label_smoothing)\n",
        "# from train_kd import train_and_evaluate, train_and_evaluate_kd\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load the parameters from json file\n",
        "    # args = parser.parse_args(argv[1:])\n",
        "    # args = parser.parse_args()\n",
        "    torch.cuda.empty_cache()\n",
        "    json_path = os.path.join(args.model_dir.rsplit('/',1)[0] , args.dataset_name + '_params.json')\n",
        "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
        "    params = Params(json_path)\n",
        "    read_params_json(json_path)\n",
        "    # Set the random seed for reproducible experiments\n",
        "    random_seeder = int(args.random_seeder)\n",
        "    print('Random Seeder :  {}'.format(random_seeder))\n",
        "    print('Dataset Name : ', args.dataset_name, '  Number of classes: ', args.num_class)\n",
        "    random.seed(random_seeder)\n",
        "    torch.manual_seed(random_seeder)\n",
        "    np.random.seed(random_seeder)\n",
        "    torch.cuda.manual_seed(random_seeder)\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # Set the logger\n",
        "    \n",
        "    if not os.path.exists(args.model_dir):\n",
        "        os.makedirs(args.model_dir)\n",
        "    logger_path = os.path.join(args.model_dir, 'train.log')  \n",
        "    set_logger(logger_path)\n",
        "    \n",
        "    # Create the input data pipeline\n",
        "    logging.info(\"Loading the datasets...\")\n",
        "\n",
        "    # fetch dataloaders, considering full-set vs. sub-set scenarios\n",
        "\n",
        "    if params.subset_percent < 1.0:\n",
        "        train_dl = fetch_subset_dataloader('train', params)\n",
        "    else:\n",
        "        train_dl = fetch_dataloader('train', params, args.dataset_name)\n",
        "\n",
        "    dev_dl = fetch_dataloader('dev', params, args.dataset_name)\n",
        "\n",
        "    logging.info(\"- done.\")\n",
        "\n",
        "    \"\"\"\n",
        "    Load student and teacher model\n",
        "    \"\"\"\n",
        "    if \"distill\" in params.model_version:\n",
        "      \n",
        "        # Specify the student models\n",
        "        if params.model_version == \"cnn_distill\":  # 5-layers Plain CNN\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = net.Net(params).to(device)\n",
        "\n",
        "        elif params.model_version == \"shufflenet_v2_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = shufflenet.shufflenetv2(class_num=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"mobilenet_v2_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = mobilenet.mobilenetv2(class_num=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == 'resnet18_distill':\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = resnet.ResNet18(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == 'resnet50_distill':\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model_name  = 'resnet50'\n",
        "            num_classes = args.num_class\n",
        "            feature_extract=False\n",
        "            model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "            model = model.to(device)\n",
        "\n",
        "        elif params.model_version == \"alexnet_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = alexnet.alexnet(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"vgg19_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = models.vgg19_bn(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"googlenet_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = googlenet.GoogleNet(num_class=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"resnext29_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model = resnext.CifarResNeXt(\n",
        "                cardinality=8, depth=29, num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"densenet121_distill\":\n",
        "            print(\"Student model: {}\".format(params.model_version))\n",
        "            model_name  = 'densenet121'\n",
        "            num_classes = args.num_class\n",
        "            feature_extract=False\n",
        "            model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "            model = model.to(device)\n",
        "            #model = densenet.densenet121(num_class=args.num_class).to(device)\n",
        "\n",
        "        # optimizer\n",
        "        if params.model_version == \"cnn_distill\":\n",
        "            optimizer = optim.Adam(model.parameters(), lr=params.learning_rate * (params.batch_size / 128))\n",
        "        else:\n",
        "            optimizer = optim.SGD(model.parameters(), lr=params.learning_rate * (params.batch_size / 128), momentum=0.9,\n",
        "                                  weight_decay=5e-4)\n",
        "\n",
        "        iter_per_epoch = len(train_dl)\n",
        "        warmup_scheduler = WarmUpLR(optimizer,iter_per_epoch * args.warm)  # warmup the learning rate in the first epoch\n",
        "\n",
        "        # specify loss function\n",
        "        if args.self_training:\n",
        "            print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>self training>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
        "            if args.swap_option == 'student_probability_swap':\n",
        "                print('------------Swapping Student Output------------')\n",
        "            elif args.swap_option == 'teacher_probability_swap':\n",
        "                print('------------Swapping Teacher Output------------')\n",
        "            loss_fn_kd = loss_kd_self\n",
        "        else:\n",
        "            loss_fn_kd = loss_kd\n",
        "\n",
        "        \"\"\" \n",
        "            Specify the pre-trained teacher models for knowledge distillation\n",
        "            Checkpoints can be obtained by regular training or downloading our pretrained models\n",
        "            For model which is pretrained in multi-GPU, use \"nn.DaraParallel\" to correctly load the model weights.\n",
        "        \"\"\"\n",
        "        \n",
        "        model_name_plus_best_pth_tar = args.dataset_name + '/best.pth.tar'\n",
        "        if params.teacher == \"resnet18\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = resnet.ResNet18(num_classes=args.num_class)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet18/' + model_name_plus_best_pth_tar\n",
        "            if args.pt_teacher:  # poorly-trained teacher for Defective KD experiments\n",
        "                teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet18/0.pth.tar'\n",
        "            teacher_model = teacher_model.to(device)\n",
        "\n",
        "        elif params.teacher == \"alexnet\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = alexnet.alexnet(num_classes=args.num_class)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_alexnet/' + model_name_plus_best_pth_tar\n",
        "            teacher_model = teacher_model.to(device)\n",
        "\n",
        "        elif params.teacher == \"googlenet\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = googlenet.GoogleNet(num_class=args.num_class)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_googlenet/' + model_name_plus_best_pth_tar\n",
        "            teacher_model = teacher_model.to(device)\n",
        "\n",
        "        elif params.teacher == \"vgg19\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = models.vgg19_bn(num_classes=args.num_class)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_vgg19/' + model_name_plus_best_pth_tar\n",
        "            teacher_model = teacher_model.to(device)\n",
        "\n",
        "        elif params.teacher == \"resnet50\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            #teacher_model = resnet.ResNet50(num_classes=args.num_class).to(device)\n",
        "            model_name  = params.teacher\n",
        "            num_classes = args.num_class\n",
        "            feature_extract=False\n",
        "            teacher_model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
        "            teacher_model = teacher_model.to(device)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet50/' + model_name_plus_best_pth_tar\n",
        "            if args.pt_teacher:  # poorly-trained teacher for Defective KD experiments\n",
        "                teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet50/50.pth.tar'\n",
        "\n",
        "        elif params.teacher == \"densenet121\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            #teacher_model = densenet.densenet121(num_class=args.num_class).to(device)\n",
        "            model_name  = params.teacher\n",
        "            num_classes = args.num_class\n",
        "            feature_extract=False\n",
        "            teacher_model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
        "            teacher_model = teacher_model.to(device)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_densenet121/' + model_name_plus_best_pth_tar\n",
        "            # teacher_model = nn.DataParallel(teacher_model).to(device)\n",
        "\n",
        "        elif params.teacher == \"resnet101\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = resnet.ResNet101(num_classes=args.num_class).to(device)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet101/' + model_name_plus_best_pth_tar\n",
        "            teacher_model = teacher_model.to(device)\n",
        "\n",
        "        elif params.teacher == \"resnext29\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = resnext.CifarResNeXt(cardinality=8, depth=29, num_classes=args.num_class).to(device)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnext29/' + model_name_plus_best_pth_tar\n",
        "            if args.pt_teacher:  # poorly-trained teacher for Defective KD experiments\n",
        "                teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnext29/50.pth.tar'\n",
        "                teacher_model = nn.DataParallel(teacher_model).to(device)\n",
        "\n",
        "        elif params.teacher == \"mobilenet_v2\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = mobilenet.mobilenetv2(class_num=args.num_class).to(device)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_mobilenet_v2/' + model_name_plus_best_pth_tar\n",
        "        \n",
        "            \n",
        "            \n",
        "\n",
        "        elif params.teacher == \"shufflenet_v2\":\n",
        "            print(\"Teacher model: {}\".format(params.teacher))\n",
        "            teacher_model = shufflenet.shufflenetv2(class_num=args.num_class).to(device)\n",
        "            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_shufflenet_v2/' + model_name_plus_best_pth_tar\n",
        "            \n",
        "            \n",
        "        print('Teacher checkpoint directory : ', teacher_checkpoint)\n",
        "        load_checkpoint(teacher_checkpoint, teacher_model)\n",
        "\n",
        "        # Train the model with KD\n",
        "        logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
        "        train_and_evaluate_kd(model, teacher_model, train_dl, dev_dl, optimizer, loss_fn_kd,warmup_scheduler, params, args, args.restore_file)\n",
        "\n",
        "    # non-KD mode: regular training to obtain a baseline model\n",
        "    else:\n",
        "        print(\"Train base model\")\n",
        "        if params.model_version == \"cnn\":\n",
        "            model = net.Net(params).to(device)\n",
        "\n",
        "        elif params.model_version == \"mobilenet_v2\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            model = mobilenet.mobilenetv2(class_num=args.num_class).to(device)\n",
        "            print(next(model.parameters()).is_cuda)\n",
        "\n",
        "        elif params.model_version == \"shufflenet_v2\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            model = shufflenet.shufflenetv2(class_num=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"alexnet\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            model = alexnet.alexnet(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"vgg19\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            model = models.vgg19_bn(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"googlenet\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            model = googlenet.GoogleNet(num_class=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"densenet121\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            # model_name  = params.model_version\n",
        "            # num_classes = args.num_class\n",
        "            # feature_extract=False\n",
        "            # model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
        "            # model = model.to(device)\n",
        "            # model = densenet.densenet121(num_class=args.num_class).to(device)\n",
        "            model = densenet121(num_class=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"resnet18\":\n",
        "            model = resnet.ResNet18(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"resnet50\":\n",
        "            print(\"model: {}\".format(params.model_version))\n",
        "            # model_name  = 'resnet50'\n",
        "            # num_classes = args.num_class\n",
        "            # feature_extract=False\n",
        "            # model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
        "            # model = model.to(device)\n",
        "        \n",
        "            \n",
        "            model = resnet.ResNet50(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"resnet101\":\n",
        "            model = resnet.ResNet101(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"resnet152\":\n",
        "            model = resnet.ResNet152(num_classes=args.num_class).to(device)\n",
        "\n",
        "        elif params.model_version == \"resnext29\":\n",
        "            model = resnext.CifarResNeXt(\n",
        "                cardinality=8, depth=29, num_classes=args.num_class).to(device)\n",
        "            # model = nn.DataParallel(model).to(device)\n",
        "\n",
        "        if args.regularization:\n",
        "            print(\">>>>>>>>>>>>>>>>>>>>>>>>Loss of Regularization>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "            loss_fn = loss_kd_regularization\n",
        "        elif args.label_smoothing:\n",
        "            print(\">>>>>>>>>>>>>>>>>>>>>>>>Label Smoothing>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "            loss_fn = loss_label_smoothing\n",
        "        else:\n",
        "            print(\">>>>>>>>>>>>>>>>>>>>>>>>Normal Training>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            if args.double_training:  # double training, compare to self-KD\n",
        "                print(\">>>>>>>>>>>>>>>>>>>>>>>>Double Training>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "                checkpoint = 'experiments/pretrained_teacher_models/base_' + str(params.model_version) + '/best.pth.tar'\n",
        "                load_checkpoint(checkpoint, model)\n",
        "\n",
        "        if params.model_version == \"cnn\":\n",
        "            optimizer = optim.Adam( model.parameters(), lr=params.learning_rate * (params.batch_size / 128))\n",
        "        else:\n",
        "            optimizer = optim.SGD(model.parameters(), lr=params.learning_rate * (params.batch_size / 128), momentum=0.9,weight_decay=5e-4)\n",
        "\n",
        "\n",
        "        iter_per_epoch = len(train_dl)\n",
        "        warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * args.warm)\n",
        "\n",
        "        # Train the model\n",
        "        logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
        "        train_and_evaluate(model, train_dl, dev_dl, optimizer, loss_fn, params, args.model_dir, warmup_scheduler, args, args.restore_file)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LiHN8qmPFBkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "dense net in pytorch\n",
        "[1] Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger.\n",
        "    Densely Connected Convolutional Networks\n",
        "    https://arxiv.org/abs/1608.06993v5\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "#\"\"\"Bottleneck layers. Although each layer only produces k\n",
        "#output feature-maps, it typically has many more inputs. It\n",
        "#has been noted in [37, 11] that a 11 convolution can be in-\n",
        "#troduced as bottleneck layer before each 33 convolution\n",
        "#to reduce the number of input feature-maps, and thus to\n",
        "#improve computational efficiency.\"\"\"\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate):\n",
        "        super().__init__()\n",
        "        #\"\"\"In  our experiments, we let each 11 convolution\n",
        "        #produce 4k feature-maps.\"\"\"\n",
        "        inner_channel = 4 * growth_rate\n",
        "\n",
        "        #\"\"\"We find this design especially effective for DenseNet and\n",
        "        #we refer to our network with such a bottleneck layer, i.e.,\n",
        "        #to the BN-ReLU-Conv(11)-BN-ReLU-Conv(33) version of H ` ,\n",
        "        #as DenseNet-B.\"\"\"\n",
        "        self.bottle_neck = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, inner_channel, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(inner_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(inner_channel, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([x, self.bottle_neck(x)], 1)\n",
        "\n",
        "#\"\"\"We refer to layers between blocks as transition\n",
        "#layers, which do convolution and pooling.\"\"\"\n",
        "class Transition(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        #\"\"\"The transition layers used in our experiments\n",
        "        #consist of a batch normalization layer and an 11\n",
        "        #convolutional layer followed by a 22 average pooling\n",
        "        #layer\"\"\".\n",
        "        self.down_sample = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.AvgPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_sample(x)\n",
        "\n",
        "#DesneNet-BC\n",
        "#B stands for bottleneck layer(BN-RELU-CONV(1x1)-BN-RELU-CONV(3x3))\n",
        "#C stands for compression factor(0<=theta<=1)\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_class=200):\n",
        "        super().__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "\n",
        "        #\"\"\"Before entering the first dense block, a convolution\n",
        "        #with 16 (or twice the growth rate for DenseNet-BC)\n",
        "        #output channels is performed on the input images.\"\"\"\n",
        "        inner_channels = 2 * growth_rate\n",
        "\n",
        "        #For convolutional layers with kernel size 33, each\n",
        "        #side of the inputs is zero-padded by one pixel to keep\n",
        "        #the feature-map size fixed.\n",
        "        self.conv1 = nn.Conv2d(3, inner_channels, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.features = nn.Sequential()\n",
        "\n",
        "        for index in range(len(nblocks) - 1):\n",
        "            self.features.add_module(\"dense_block_layer_{}\".format(index), self._make_dense_layers(block, inner_channels, nblocks[index]))\n",
        "            inner_channels += growth_rate * nblocks[index]\n",
        "\n",
        "            #\"\"\"If a dense block contains m feature-maps, we let the\n",
        "            #following transition layer generate m output feature-\n",
        "            #maps, where 0 <   1 is referred to as the compression\n",
        "            #fac-tor.\n",
        "            out_channels = int(reduction * inner_channels) # int() will automatic floor the value\n",
        "            self.features.add_module(\"transition_layer_{}\".format(index), Transition(inner_channels, out_channels))\n",
        "            inner_channels = out_channels\n",
        "\n",
        "        self.features.add_module(\"dense_block{}\".format(len(nblocks) - 1), self._make_dense_layers(block, inner_channels, nblocks[len(nblocks)-1]))\n",
        "        inner_channels += growth_rate * nblocks[len(nblocks) - 1]\n",
        "        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
        "        self.features.add_module('relu', nn.ReLU(inplace=True))\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.linear = nn.Linear(inner_channels, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.features(output)\n",
        "        output = self.avgpool(output)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "    def _make_dense_layers(self, block, in_channels, nblocks):\n",
        "        dense_block = nn.Sequential()\n",
        "        for index in range(nblocks):\n",
        "            dense_block.add_module('bottle_neck_layer_{}'.format(index), block(in_channels, self.growth_rate))\n",
        "            in_channels += self.growth_rate\n",
        "        return dense_block\n",
        "\n",
        "def densenet121(**kwargs):\n",
        "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32, **kwargs)\n",
        "\n",
        "def densenet169(**kwargs):\n",
        "    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32,**kwargs)\n",
        "\n",
        "def densenet201(**kwargs):\n",
        "    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32, **kwargs)\n",
        "\n",
        "def densenet161(**kwargs):\n",
        "    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48, **kwargs)\n"
      ],
      "metadata": {
        "id": "2iwjGzSHM9Pp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "dynamic_rectification_knowledge_distillation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}